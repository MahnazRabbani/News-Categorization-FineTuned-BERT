{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words and Naive Bayes Classifier    \n",
    "\n",
    "Here the goal is to try the Naive Bayes classifier with the BoW method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is bag of words anyway?     \n",
    "\n",
    "The Bag of Words (BoW) method is a popular way to **represent text data** in machine learning, which treats **each document as an unordered collection** or \"bag\" of words. This method is used for feature extraction in text data. \n",
    "\n",
    "In the Bag of Words method, **a text** (such as a sentence or a document) **is represented as the bag (multiset) of its words**, **disregarding grammar** and even **word order** but **keeping multiplicity**. The **frequency of each word** is used as a **feature** for training a classifier.        \n",
    "\n",
    "## How does it work?       \n",
    "\n",
    "1. **Tokenization**: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation. In this project our dadaset is already splited in sentences and is labeled.          \n",
    "\n",
    "2. **Vocabulary building**: All the words are collected and a dictionary is created where words are key and the indexes are values. The length of the dictionary is the length of the individual text representation.\n",
    "\n",
    "3. **Text to Vector**: Each sentence or document is converted into a vector of length equal to vocabulary. The presence of word from the vocabulary in the text will make the respective position in the vector 1, and if the word is absent the position will be 0. If 'n' number of times a word occurs in the text, the respective position's value will be 'n'.\n",
    "\n",
    "For example, let's consider two sentences:\n",
    "- Sentence 1: \"The cat sat on the mat.\"\n",
    "- Sentence 2: \"The dog sat on the log.\"\n",
    "\n",
    "In a BoW model, these sentences would first be tokenized into:\n",
    "\n",
    "- Sentence 1: [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "- Sentence 2: [\"The\", \"dog\", \"sat\", \"on\", \"the\", \"log\"]\n",
    "\n",
    "Then, the vocabulary of unique words would be: [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"dog\", \"log\"]\n",
    "\n",
    "Lastly, the sentences would be transformed into vectors based on this vocabulary:\n",
    "\n",
    "- Sentence 1: [2, 1, 1, 1, 1, 0, 0]\n",
    "- Sentence 2: [2, 0, 1, 1, 0, 1, 1]\n",
    "\n",
    "As you can see, each index in the vector corresponds to a word in the vocabulary, and the value at each index corresponds to the number of times that word appears in the sentence. \n",
    "\n",
    "The BoW approach is simple and effective, but it has some downsides. It creates sparse vectors because the length of the vector is the same as the length of the vocabulary, and for each sentence or document, many positions will be zero if the word is not present in the document. Also, this approach doesn't account for word order or context, so it might not be as effective for tasks where these elements are important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the dataset, then, we convert the training data into a list of strings, and after that we pass the list to **CountVectorizer**. CountVectorizer transforms the text data into a bag of words representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/mahnaz/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 326.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#reading the dataset\n",
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys:  dict_keys(['train', 'test'])\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['World', 'Sports', 'Business', 'Sci/Tech'], id=None)}\n",
      "example of train datapoint: \n",
      " {'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# lets first have a look at the data\n",
    "print(\"keys: \",raw_datasets.keys())\n",
    "print(type(raw_datasets['train']))\n",
    "print(raw_datasets['train'].features)\n",
    "print(f\"example of train datapoint: \\n {raw_datasets['train'][0]}\")\n",
    "print(raw_datasets['train'][0]['text'])\n",
    "print(raw_datasets['train'][0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
      "{'text': 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', 'label': 2}\n",
      "{'text': \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\", 'label': 2}\n",
      "{'text': 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.', 'label': 2}\n",
      "{'text': 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.', 'label': 2}\n",
      "{'text': 'Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\\\but stayed near lows for the year as oil prices surged past  #36;46\\\\a barrel, offsetting a positive outlook from computer maker\\\\Dell Inc. (DELL.O)', 'label': 2}\n",
      "{'text': \"Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\", 'label': 2}\n",
      "{'text': 'Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.', 'label': 2}\n",
      "{'text': 'Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.', 'label': 2}\n",
      "{'text': \"Wall St. Bears Claw Back Into the Black  NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\", 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "# printing the first 10 lines of the data:\n",
    "for i in range(10):\n",
    "    print(raw_datasets['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data into list of strings\n",
    "train_texts = [example['text'] for example in raw_datasets['train']]\n",
    "train_labels = [example['label'] for example in raw_datasets['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CountVectorizer transforms each text into a vector in a high-dimensional space. The dimension of this space is equal to the size of the learned vocabulary (i.e., the number of unique words in all documents of the training data). Each unique word has its own dimension and the value in that dimension is the count of this word in the corresponding document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn a vocabulary dictionary of all tokens in the raw documents and return term-document matrix\n",
    "X_train = vectorizer.fit_transform(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (120000, 65006)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "  (0, 62536)\t2\n",
      "  (0, 54842)\t1\n",
      "  (0, 7396)\t1\n",
      "  (0, 12600)\t1\n",
      "  (0, 6510)\t1\n",
      "  (0, 30178)\t1\n",
      "  (0, 57946)\t1\n",
      "  (0, 8345)\t1\n",
      "  (0, 48864)\t2\n",
      "  (0, 52479)\t1\n",
      "  (0, 51606)\t1\n",
      "  (0, 55636)\t1\n",
      "  (0, 18921)\t1\n",
      "  (0, 6832)\t1\n",
      "  (0, 40992)\t1\n",
      "  (0, 60125)\t1\n",
      "  (0, 15556)\t1\n",
      "  (0, 5306)\t1\n",
      "  (0, 51513)\t1\n",
      "  (0, 25524)\t1\n",
      "  (0, 3522)\t1\n"
     ]
    }
   ],
   "source": [
    "type(X_train)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(type(X_train[0]))\n",
    "print(X_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** \n",
    "\n",
    "The above output is a representation of a sparse matrix in the Compressed Sparse Row (CSR) format. Let's break down the information:\n",
    "\n",
    "The type of the object (that is a matrix representation of a datapoint/sentence), is a sparse matrix in CSR format from the SciPy library (`<class 'scipy.sparse._csr.csr_matrix'>`)\n",
    "\n",
    "Following that, there are multiple lines with a specific format `(row_index, column_index) value`. These lines **represent the non-zero elements of the sparse matrix**. Here's an explanation of each line:\n",
    "\n",
    "- `(0, 7250) 2`: This line indicates that the value `2` is present at row index `0` and column index `7250`.        \n",
    "- `(0, 6270) 1`: This line indicates that the value `1` is present at row index `0` and column index `6270`.         \n",
    "- `(0, 738) 1`: This line indicates that the value `1` is present at row index `0` and column index `738`.          \n",
    "- ...         \n",
    "\n",
    "Each subsequent line follows the same pattern, representing the row index, column index, and value of a non-zero element in the sparse matrix.         \n",
    "\n",
    "In summary, this output is a **representation of a sparse matrix in CSR format**, where the **non-zero elements are shown with their corresponding row and column indices**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert labels to a numpy array for later use with Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train:  (120000,)\n",
      "<class 'numpy.int64'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(type(y_train[10]))\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0 1 2 3]\n",
      "Counts: [30000 30000 30000 30000]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(\"Counts:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try the Naive Bayes classifier with a small sample of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/mahnaz/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 383.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0 1 2 3]\n",
      "Counts: [212 142 174 472]\n",
      "Accuracy: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "raw_datasets = load_dataset(\"ag_news\")\n",
    "\n",
    "# Select the first 1000 samples\n",
    "train_subset = raw_datasets['train'].select(range(1000))\n",
    "\n",
    "\n",
    "# Convert the train data into list of strings\n",
    "train_texts = train_subset['text']\n",
    "train_labels = train_subset['label']\n",
    "\n",
    "# Initialize a CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform the train data into the BoW representation\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Printing the counts of each class to make sure all classes have datapoints\n",
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(\"Counts:\", counts)\n",
    "\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "naive_bayes_clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "naive_bayes_clf.fit(X_train, y_train)\n",
    "\n",
    "# Select the first 1000 samples from test set\n",
    "test_subset = raw_datasets['test'].select(range(1000))\n",
    "\n",
    "# Convert the test data into list of strings\n",
    "test_texts = test_subset['text']\n",
    "test_labels = test_subset['label']\n",
    "\n",
    "# Transform the test data into the BoW representation\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = naive_bayes_clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a 0.72 accuracy with Naive Bayes algorithm which shows weaker prediction power in compare to accuracy of 0.885 with fine-tuned BERT. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TF-IDF and Naive Bayes Classifier\n",
    "\n",
    "Now lets try the Naive Bayes classifier with the TF-IDF method and compare the accuracy with BoW method.\n",
    "\n",
    "## What is the TF-IDF?\n",
    "\n",
    "TF-IDF stands for **Term Frequency-Inverse Document Frequency**, and it's a **numerical statistic** used to reflect **how important a word is to a document** in a collection or corpus. It's one of the most popular techniques used for information retrieval to represent how important a specific word or phrase is to a given document.       \n",
    "\n",
    "TF-IDF is a combination of two concepts: term frequency (TF) and inverse document frequency (IDF):\n",
    "\n",
    "**Term Frequency (TF)**: This measures the **frequency of a word in a document**. That is, if a word appears more times in a document, its TF will increase. It is given by:    \n",
    "\n",
    "**TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)**     \n",
    "\n",
    "**Inverse Document Frequency (IDF)**: This measures the **importance of a word in the entire corpus**. If a word appears in many documents, it's not a unique identifier, therefore, these words are usually less important. It is given by:\n",
    "\n",
    "**IDF(t) = log_e(Total number of documents / Number of documents with term t in it)**\n",
    "\n",
    "The **TF-IDF** value is obtained by multiplying these two quantities: **TF * IDF**. This will increase proportionally to the number of times a word appears in the document but is offset by the number of documents in the corpus that contain the word.\n",
    "\n",
    "What this technique does is, it **rescales the frequency of words by how often they appear in all documents**, so that the scores for frequent words like \"the\" that are also frequent across all documents are penalized. This allows for words that are more unique to the document to hold more weight, which can improve the performance of many text mining tasks like text classification, clustering, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/mahnaz/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 436.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF and Naive Bayes Classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"ag_news\")\n",
    "\n",
    "train_subset = raw_datasets['train'].select(range(1000))\n",
    "test_subset = raw_datasets['test'].select(range(1000))\n",
    "\n",
    "train_texts = [example['text'] for example in train_subset]\n",
    "train_labels = [example['label'] for example in train_subset]\n",
    "test_texts = [example['text'] for example in test_subset]\n",
    "test_labels = [example['label'] for example in test_subset]\n",
    "\n",
    "# Apply the TF-IDF Vectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vect.fit_transform(train_texts)\n",
    "X_test_tfidf = tfidf_vect.transform(test_texts)\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(f\"Accuracy: {metrics.accuracy_score(test_labels, predicted)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Naive Bayes with TF-IDF is much lower than the fine-tubed BERT and Naive Bayes with BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tfidf)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 306)\t0.1892144669935855\n",
      "  (0, 2984)\t0.22803951498848163\n",
      "  (0, 5840)\t0.2222928298136565\n",
      "  (0, 508)\t0.11395365544824688\n",
      "  (0, 1755)\t0.25387980729831355\n",
      "  (0, 6999)\t0.25387980729831355\n",
      "  (0, 4539)\t0.05940129262366908\n",
      "  (0, 684)\t0.22803951498848163\n",
      "  (0, 2167)\t0.24315511699740658\n",
      "  (0, 6389)\t0.2021992226786497\n",
      "  (0, 5855)\t0.24315511699740658\n",
      "  (0, 5972)\t0.20544297736560763\n",
      "  (0, 5569)\t0.2041636162525598\n",
      "  (0, 838)\t0.2089961086129379\n",
      "  (0, 6724)\t0.04471510643864858\n",
      "  (0, 3479)\t0.13808618375812984\n",
      "  (0, 657)\t0.1706122451939926\n",
      "  (0, 1357)\t0.25387980729831355\n",
      "  (0, 738)\t0.2348364009227698\n",
      "  (0, 6270)\t0.21292391297955668\n",
      "  (0, 7250)\t0.4043984453572994\n"
     ]
    }
   ],
   "source": [
    "# how does a matrix representation of a document look like in TF-IDF?\n",
    "print(X_train_tfidf[0] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with TF-IDF \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/mahnaz/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 412.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71       268\n",
      "           1       0.94      0.61      0.74       274\n",
      "           2       0.74      0.49      0.59       205\n",
      "           3       0.53      0.94      0.68       253\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.74      0.68      0.68      1000\n",
      "weighted avg       0.75      0.68      0.68      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "raw_datasets = load_dataset(\"ag_news\")\n",
    "train_subset = raw_datasets['train'].select(range(1000))\n",
    "test_subset = raw_datasets['test'].select(range(1000))\n",
    "\n",
    "# Prepare training data\n",
    "train_texts = [example['text'] for example in train_subset]\n",
    "train_labels = [example['label'] for example in train_subset]\n",
    "\n",
    "# Prepare test data\n",
    "test_texts = [example['text'] for example in test_subset]\n",
    "test_labels = [example['label'] for example in test_subset]\n",
    "\n",
    "# Initialize a TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Define MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "\n",
    "# Train the classifier\n",
    "mlp.fit(X_train, train_labels)\n",
    "\n",
    "# Test the classifier\n",
    "predicted = mlp.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(test_labels, predicted))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with BERT vectorization (feature extraction)   \n",
    "\n",
    "Using BERT for vectorization (also known as feature extraction) and MLP as a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/mahnaz/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 414.27it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80       268\n",
      "           1       0.90      0.87      0.88       274\n",
      "           2       0.78      0.42      0.55       205\n",
      "           3       0.64      0.89      0.74       253\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.78      0.75      0.74      1000\n",
      "weighted avg       0.78      0.77      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "raw_datasets = load_dataset(\"ag_news\")\n",
    "train_subset = raw_datasets['train'].select(range(1000))\n",
    "test_subset = raw_datasets['test'].select(range(1000))\n",
    "\n",
    "# Prepare training data\n",
    "train_texts = [example['text'] for example in train_subset]\n",
    "train_labels = [example['label'] for example in train_subset]\n",
    "\n",
    "# Prepare test data\n",
    "test_texts = [example['text'] for example in test_subset]\n",
    "test_labels = [example['label'] for example in test_subset]\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# BERT Vectorization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    train_features = model(**train_encodings)['pooler_output'].numpy()\n",
    "\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    test_features = model(**test_encodings)['pooler_output'].numpy()\n",
    "\n",
    "# Define MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "\n",
    "# Train the classifier\n",
    "mlp.fit(train_features, train_labels)\n",
    "\n",
    "# Test the classifier\n",
    "predicted = mlp.predict(test_features)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(test_labels, predicted))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this small sample of data, MLP works better with BERT feature extraction (accuracy of 0.77) compared to TF-IDF vectorization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_News-Categorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2f579e51b388ca38e2e9f7d7a1e721a01ca5e6a35b59bd63e5175d6a356866"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
